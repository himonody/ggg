### 索引

#### 数据库设计

三大范式就是一个字段做一个字段该做的事，一个表做一个表该干的事，拒绝冗余，但是如果没有完全冗余就会引起多表join，增加适当冗余可以提高查询性能，一般冗余的是不太发生变化的字段，当不可避免join的时候可以设计一个中间表去存储所有数据，用了中间表呢就要设计好更新机制，避免出现数据不一致的情况，最好能有定期轮询检查，第三字段长度最好设计合理一些，一些枚举数字能用tinyint 就不用smallint，varchar长度最好是2的次方

#### 数据结构

**索引是一种数据结构，B+树非叶子节点存索引适合放在内存中，叶子节点存放数据并且用双向链表连接适合范围查询，**锁是借助索引来实现的。或者说，加锁锁住的其实是索引项，更加具体地来说，就是锁住了叶子节点

#### 回表

聚簇索引的时候，索引找到主键，然后用主键再去聚簇索引查询，可以用**覆盖索引优化****，****索引下推**通过在索引阶段尽早过滤不匹配的行，减少回表次数，提高查询效率

**最左匹配：左比右区分度高，权重高**

#### 什么是索引？索引分类？

**话术：**从数据结构上来说，在 MySQL 里面索引主要是 B+ 树索引。它的查询性能更好，适合范围查询，也适合放在内存里。 MySQL 的索引又可以从不同的角度进一步划分。比如说根据叶子节点是否包含数据分成聚簇索引和非聚簇索引，还有包含某个查询的所有列的覆盖索引等等。数据库使用索引遵循最左匹配原则。但是最终数据库会不会用索引，也是一个比较难说的事情，跟查询有关，也跟数据量有关。在实践中，是否使用索引以及使用什么索引，都要以 EXPLAIN 为准。

#### 为什么不用二分查找，跳表，二叉树，hash，红黑树？

**话术：**B+树非叶子节点存储索引，叶子节点存储数据并且用双向链表连接，适合单点查询和范围查询，而哈希，二分查找只支持单点查询，节点大，层级浅，可以减少磁盘io充分利用了磁盘预读和缓存机制，二叉树，红黑树，跳表层级太深，会有大量随机io。

#### Explain

- **type：**system 和 const 都可以理解为数据库只会返回一行数据，所以查询时间是固定的。**eq_ref 和 ref** 根据索引的值来查找。**range**：索引范围扫描。**index：**索引全表扫描，也就是扫描整棵索引。**ALL：**全表扫描，发起磁盘 IO 的那种全表扫描。
- **possible_keys：**候选的索引。
- **key：**实际使用的索引。
- **rows**：扫描的行数。

**设计索引****：频繁where、order by和区分度高的列**

**索引代价****：主要的代价是增删改的时候会同步维护索引，影响效率**

**索引失效：**使用左模糊匹配，索引列使用函数、计算、隐式转换，or都使用范围查询，索引字段用了is not null，in了很多数据，not in 非主键字段，not exsit所有字段，or全表扫描字段，或者order by 全表数据，联合索引不遵守最左匹配

#### MySQL 单表不要超过 2000W 行，靠谱吗？

**话术：**MySQL表数据以页来存储在磁盘不一定是连续的，页空间16k除了存储数据还有其他页头，页尾，校验的信息，B+树索引中非叶子节点存主键和页号，叶子节点存储数据，索引结构不会影响单表最大行数，2000w只是推荐值，超过这个值树的层级更高影响查询性能

### 事务

#### 事务特性ACID

原子性A：undo log保证，事务操作要么全部完成要么全部

隔离性：MVCC（多版本并发控制） 或锁机制保证，事务之间完全隔离

持久性：redo log保证事务结束后，对数据的修改是永久的

一致性：事务操作前后，数据满足完整性约束，数据库保持一致性状态

#### 并行事务会引发什么问题？

脏读：读到其他事务未提交的数据，

不可重复读：前后读取的数据不一致;

幻读：前后读取的记录数量不一致。

#### 事务隔离级别有哪些？

读未提交：事务未提交的记录被其他事务看到，可能发生脏读，不可重复读，幻读现象

读已提交：事务提交的记录才能被其他事务看到，可能发生不可重复读，幻读现象

可重复读：同一个事务内多次读取的记录一致（innodb默认，mvcc实现），可能发生幻读现象

串行化：记录加读写锁

#### MVCC如何实现的？

MVCC 主要是借助于版本链来实现的。在 InnoDB 引擎里面，每一行都有两个额外的列，一个是 trx_id，代表的是修改这一行数据的事务 ID。另外一个是 roll_ptr，代表的是回滚指针。InnoDB 引擎通过回滚指针，将数据的不同版本串联在一起，也就是版本链。这些串联起来的历史版本，被放到了 undolog 里面。当某一个事务发起查询的时候，MVCC 会根据事务的隔离级别来生成不同的 Read View，从而控制事务查询最终得到的结果。

**读视图在可重复读如何工作的**：启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read view。

**读视图在读已提交如何工作的：**读取数据时，都会生成一个新的 Read View

#### MVCC 只作用于已提交读和可重复读，那么 InnoDB 是怎么处理其他两个隔离级别的？

读未提交：直接读取最新的数据行，不使用 MVCC，也不加锁。允许脏读，性能较高，但数据一致性较差。 串行化：通过加锁机制（共享锁、排他锁和间隙锁）来实现完全隔离，防止脏读、不可重复读和幻读。数据一致性最高，但并发性能较低。

#### 如何解决幻读？

针对**快照读(普通 select 语句)**，是通过 **MVCC 方式解决了幻读，可重复读没有完成解决幻读，提升隔离级别为读已提交**

针对**当前读(select. .. for update 等语句)**，是通过 **next-keylock(记录锁+间隙锁)方式解决了幻读**

**MySQL innodb不是直接操作磁盘，而是先读buffer pool，然后把修改过的刷新磁盘**

**undo log（结合mvcc），存储了版本链，用于回滚操作，1.实现了原子性，2.读视图+undolog实现MVCC**

**insert：记录了主键，回滚时根据主键删除对应的记录，**

**delete：记录了主键，回滚时根据主键标记删除位置为false，**

**update：有更新主键，删除原记录插入新记录，如果没有更新主键，记录原记录的主键和被修改的列的原值**

**redo log和undolog 区别：undolog记录事务更新前的数据状态，redolog记录事务更新后的数据状态**

redolog：用于系统恢复数据，只要刷盘成功就可以恢复，顺序写，wal，先写日志再写磁盘

redo log 是直接一步到位写到磁盘的吗？

并不是的，redo log 本身也是先写进 redo log buffer，后面再刷新到操作系统的 page cache，或者一步到位刷新到磁盘。

刷盘时机？

根据 innodb_flush_log_at_trx_commit来设置，0：从redo log buffer每秒刷磁盘，1：每次提交刷磁盘2：每次提交的时候刷新到 page cache，后续操作系统自动刷磁盘，还有两种情况redo log buffer满了也会触发刷盘机制，事务提交后触发所有的刷盘机制

事务执行流程： 1、读取并锁定目标行； 2、写undo log； 3、更新目标值到buffee pool； 4、写redo log； 5、如果innodb_flush_log_at_trx_commit设置为1，那么更新redo log到磁盘； 6、刷新buffer pool到磁盘。

### 锁

#### MySQL怎么加行锁的？

- **唯一索引 + 等值查询**：数据存在加行锁（Record Lock），不存在加Next-Key Lock
- **唯一索引 + 范围查询**：数据存在和不存在都加 Next-Key Lock，锁定匹配行及其间隙，防止幻读。
- **非唯一索引 + 等值查询**：数据存在和不存在加 Next-Key Lock，锁定所有匹配行及其间隙，防止幻读。
- **非唯一索引 + 范围查询**：数据存在和不存在加 Next-Key Lock，锁定匹配行及其间隙，防止幻读。
- **没有索引的查询**：加表锁，锁定整张表，影响并发性能，适合小表或全表操作场景。 锁定整个表，防止其他事务插入或修改数据。

#### 你知道 MySQL 的锁机制吗？你了解 MySQL 的锁吗？

MySQL 里面的锁机制特别丰富，这里我以 InnoDB 引擎为例。首先，从锁的范围来看，可以分成行锁和表锁。其次，从排它性来看，可以分成排它锁和共享锁。还有意向锁，结合排它性，就分为排它意向锁和共享意向锁。还有三个重要的锁概念，记录锁、间隙锁和临键锁。记录锁，是指锁住某条记录；间隙锁，是指锁住两条记录之间的位置；临键锁可以看成是记录锁与间隙锁的组合情况。 还有一种分类方法，是乐观锁和悲观锁。那么在数据库里面使用乐观锁，本质上是一种应用层面的 CAS 操作。在 MySQL 的 InnoDB 引擎里面，锁和索引、隔离级别都是有密切关系的。在 InnoDB 引擎里面，锁是依赖于索引来实现的。或者说，锁都是加在索引项上的。因此，如果一个查询用了索引，那么会用行锁，如果没用到任何索引，那么就会用表锁。此外，在 MySQL 里面，间隙锁和临键锁是只工作在可重复读这个隔离级别下的。

#### 锁优化案例

早期我发现我们的业务有一个的性能问题，就是响应时间偶尔会突然延长。后来经过我们排查，确认响应时间是因为数据库查询变慢引起的。但是这些变长的查询，SQL 完全没有问题，我用 EXPLAIN 去分析，都很正常，也走了索引。 直到后面我们去排查业务代码的提交记录，才发现新加了一个功能，这个功能会执行一个 SQL，但是这个 SQL 本身不会命中任何索引。于是数据库就会使用表锁，偏偏这个 SQL 因为本身没有命中索引，又很慢，导致表锁一直得不到释放。结果其他正常的 SQL 反而被它拖累了。最终我们重新优化了这个使用表锁的 SQL，让它走了一个索引，就解决了这个问题。

#### 临键锁引发的死锁和弃用悲观锁

早期我优化过一个死锁问题，是临键锁引起的。业务逻辑很简单，先用 SELECT FOR UPDATE 查询数据。如果查询到了数据，那么就执行一段业务逻辑，然后更新结果；如果没有查询到，那么就执行另外一段业务逻辑，然后插入计算结果。 那么如果 SELECT FOR UPDATE 查找的数据不存在，那么数据库会使用一个临键锁。此时，如果有两个线程加了临键锁，然后又希望插入计算结果，那么就会造成死锁。 我这个优化也很简单，就是上来先不管三七二十一，直接插入数据。如果插入成功，那么就执行没有数据的逻辑，此时不会再持有临键锁，而是持有了行锁。如果插入不成功，那么就执行有数据的业务逻辑。 此外，还有两个思路。一个是修改数据库的隔离级别为 RC，那么自然不存在临键锁了，但是这个修改影响太大，被 DBA 否决了。另外一个思路就是使用乐观锁，不过代码改起来要更加复杂，所以就没有使用。

#### 弃用悲观锁案例（聊乐观锁可以讲到）

我在入职这家公司之后，曾经系统地清理过公司内部使用悲观锁的场景，改用乐观锁。正常的悲观锁都是使用了 SELECT FOR UPDATE 语句，查询到数据之后，进行一串计算，再将结果写回去。那么改造的方案很简单，查询的时候使用 SELECT 语句直接查询，然后进行计算。但是在写回去的时候，就要用到数据库的 CAS 操作，即 UPDATE 的时候要确认之前查询出来的结果并没有实际被修改过。 一般来说就是 UPDATE xxx SET data = newData WHERE id = 1 AND data = oldData。这种改造效果非常好，性能提升了 30%。当然，并不是所有的悲观锁场景都能清理，还有一部分实在没办法，只能是考虑别的手段了。

### 分库分表

### 分布式事务

### 数据迁移
